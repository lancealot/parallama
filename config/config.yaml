server:
  host: 0.0.0.0
  port: 8000
  workers: 4

database:
  host: localhost
  port: 5432
  name: parallama
  user: parallama

redis:
  host: localhost
  port: 6379
  db: 0

authentication:
  access_token_expire_minutes: 30
  refresh_token_expire_days: 30
  password_hash_rounds: 12
  refresh_token_rate_limit: 5
  refresh_token_reuse_window: 60
  refresh_token_cleanup_interval: 3600

api_gateways:
  enabled:
    - ollama
    - openai
  
  discovery:
    enabled: true
    cache_ttl: 300
    include_metrics: true
  
  ollama:
    host: http://localhost
    port: 11434
    base_path: /ollama/v1
    default_model: llama2
  
  openai:
    base_path: /openai/v1
    compatibility_mode: true
    model_mappings:
      gpt-3.5-turbo: llama2
      gpt-4: llama2:70b
    token_counter:
      enabled: true
      cache_size: 1000
      cache_ttl: 3600
    performance:
      connection_pool_size: 100
      request_timeout: 60
      max_retries: 3
      batch_size: 10
    endpoints:
      chat: true
      completions: true
      embeddings: false
      edits: false
      moderations: false

logging:
  level: INFO
  dir: /var/log/parallama
  max_size: 100M
  backup_count: 10
